20/03/15 18:00:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Spark context Web UI available at http://Harsh-Komal:4040
Spark context available as 'sc' (master = local[*], app id = local-1584275417659).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.4.3
      /_/

Using Scala version 2.11.12 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_201)
Type in expressions to have them evaluated.
Type :help for more information.

scala> val auth= spark.read .format("csv") .option("header", "true").load("E:/soc_gen/problem2/auth.csv")
auth: org.apache.spark.sql.DataFrame = [auth_code: string, subreq_id: string ... 148 more fields]

scala> auth.registerTempTable("AuthAadhar")
warning: there was one deprecation warning; re-run with -deprecation for details
20/03/15 18:00:48 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.

scala> val sqlContext = new org.apache.spark.sql.SQLContext(sc)
warning: there was one deprecation warning; re-run with -deprecation for details
sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@7324d83

scala> import sqlContext.implicits._
import sqlContext.implicits._

scala> val checkInt: (String) => Int = (SA) => {
     |     try {
     | (SA.toInt)
     | } catch {
     | case e: NumberFormatException => -1
     | } }
checkInt: String => Int = <function1>

scala>

scala> spark.udf.register("isSAInt", checkInt)
res1: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,IntegerType,Some(List(StringType)))

scala> val df =sqlContext.sql("select sa , isSAInt(sa) from AuthAadhar where aua >650000 and res_state_name <>'Delhi' and isSAInt(sa) <>-1 ")
20/03/15 18:02:14 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
df: org.apache.spark.sql.DataFrame = [sa: string, UDF:isSAInt(sa): int]

scala> df.show
+------+---------------+
|    sa|UDF:isSAInt(sa)|
+------+---------------+
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
|740000|         740000|
+------+---------------+
only showing top 20 rows
